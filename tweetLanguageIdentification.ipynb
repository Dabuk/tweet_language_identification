{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data, I'm using a different delimiter, modified \\t delimiter in original  data..loading data using \\t delimiter is buggy..\n",
    "## multiple lines get appended to one line.. example..if i recollect, it's at line 288 or 287 - when original data\n",
    "## was loaded using \\t delimiter\n",
    "## even after this had to manually modify line 458 in train data..buggy line of text\n",
    "\n",
    "df = pd.read_csv('train.tsv',delimiter='\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-',encoding='utf-8',header=None)\n",
    "df_val = pd.read_csv('val.tsv',delimiter='\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-',encoding='utf-8',header=None)\n",
    "df_test = pd.read_csv('test_no_id.tsv',delimiter='\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-\\+\\-',encoding='utf-8',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoising data\n",
    "# remove http links, emojis, numbers and punctuations\n",
    "\n",
    "http_sub=re.compile(r\"http\\S+\")\n",
    "\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U0001f199-\\U0001f918\"\n",
    "        u\"\\U0001f0cf-\\U000fec2c\"\n",
    "        u\"\\u0101-\\uffffe3\"\n",
    "        \"0123456789!@#$$%^&*(){}|+_\\-=\\\"\\';:/?.,<>~`\\]\\[\"                   \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## denoise train data\n",
    "for i in range(len(df)):\n",
    "    #print i\n",
    "    #print \"original\"\n",
    "    #print temp\n",
    "    #print \"processed\"\n",
    "    #print i\n",
    "    #print df[1][i]\n",
    "    temp = df[1][i].decode('utf-8')#.lower()#.split('\\n')[0].lower() # choose only first line  and convert to lower case\n",
    "    temp = emoji_pattern.sub('',temp)\n",
    "    temp = http_sub.sub('',temp)\n",
    "    #temp = '<S> ' + temp + ' </S>'\n",
    "    df[1][i] = temp#.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## denoise val data\n",
    "N_val = 0 # total number of characters\n",
    "for i in range(len(df_val)):\n",
    "    #print i\n",
    "    #print \"original\"\n",
    "    #print temp\n",
    "    #print \"processed\"\n",
    "    #print i\n",
    "    \n",
    "    temp = df_val[1][i].decode('utf-8')#.lower()#.split('\\n')[0].lower() # choose only first line  and convert to lower case\n",
    "    temp = emoji_pattern.sub('',temp)\n",
    "    temp = http_sub.sub('',temp)\n",
    "    #temp = '<S> ' + temp + ' </S>'\n",
    "    #print df_val[1][i]\n",
    "    df_val[1][i] = temp#.decode('utf-8')\n",
    "    N_val = N_val + len(df_val[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## denoise test data\n",
    "N_test = 0 # total number of characters\n",
    "for i in range(len(df_test)):\n",
    "    #print i\n",
    "    #print \"original\"\n",
    "    #print temp\n",
    "    #print \"processed\"\n",
    "    #print i\n",
    "    \n",
    "    temp = df_test[0][i].decode('utf-8')#.lower()#.split('\\n')[0].lower() # choose only first line  and convert to lower case\n",
    "    temp = emoji_pattern.sub('',temp)\n",
    "    temp = http_sub.sub('',temp)\n",
    "    #temp = '<S> ' + temp + ' </S>'\n",
    "    df_test[0][i] = temp#.decode('utf-8')\n",
    "    N_test = N_test + len(df_test[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort train data in descending order - helpful in batching\n",
    "s = df[1].str.len().sort_values(ascending = False).index\n",
    "df = df.reindex(s).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create vocab from train data\n",
    "tempdict = {}\n",
    "for i in range(len(df)):\n",
    "    chars = list(df[1][i])\n",
    "    for j in range(len(chars)):\n",
    "        if chars[j] not in tempdict:\n",
    "            tempdict[chars[j]] = 1\n",
    "        else:\n",
    "            tempdict[chars[j]] += 1\n",
    "\n",
    "vocab = { k: v for k, v in tempdict.iteritems() if v >= 10 }\n",
    "\n",
    "vocab['<S>'] = len(df)\n",
    "vocab['</S>'] = len(df)\n",
    "vocab['EOS'] = 1 #added for padding #equated to 1 to avoid log(0) errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create out of vocab list\n",
    "oovlist = []\n",
    "vocab['unk'] = 0\n",
    "num_oov = 0\n",
    "for k,v in tempdict.iteritems():\n",
    "    if v<10:\n",
    "        vocab['unk'] += v\n",
    "        oovlist.append(k)\n",
    "        num_oov +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print oovlist\n",
    "print \"length of out of vocabulary\", len(oovlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print vocab\n",
    "print \"length of vocabulary\", len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out of vocabulary #without denoising it's 64%\n",
    "print \"Percentage out of vocabulary characters\", len(oovlist)*100.0/len(tempdict), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1b\n",
    "## calculate probability of each character in train data\n",
    "\n",
    "charprob = {}\n",
    "N = sum(vocab.values()) # total number of characters\n",
    "for k,v in vocab.iteritems():\n",
    "    charprob[k] = v*1.0/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to calculate perplexity of each model\n",
    "def logpofs(s,chp):\n",
    "    chars = list(s)\n",
    "    tempsum = 0\n",
    "    for char in chars:\n",
    "        if char in vocab:\n",
    "            tempsum = tempsum + np.log2(chp[char])\n",
    "        else:\n",
    "            tempsum = tempsum + np.log2(chp['unk'])\n",
    "    tempsum = tempsum + np.log2(chp['</S>'])\n",
    "    return tempsum\n",
    "\n",
    "def perplexity(df, N, chp):\n",
    "    probsum = 0\n",
    "    for i in range(len(df)):\n",
    "        sentence = df[1][i]\n",
    "        probsum = probsum + logpofs(sentence,chp)\n",
    "    return 2**(-1 * probsum / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train perplexity\n",
    "print perplexity(df,N,charprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## val perplexity calc using train vocab probability distribution\n",
    "print perplexity(df_val,N_val,charprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create character onehot vectors / indices for embedding layer in model\n",
    "temp = np.asarray(range(len(vocab)))\n",
    "onehots_vocab = np_utils.to_categorical(temp)\n",
    "vocabOnehotID = {}\n",
    "vocabindexID = {}\n",
    "i=0\n",
    "for keys in vocab.keys():\n",
    "    vocabOnehotID[keys] = onehots_vocab[i]\n",
    "    vocabindexID[keys] = i\n",
    "    i=i+1\n",
    "    \n",
    "# language onehot vectors / indices for embedding layer in model\n",
    "langOnehotID = {}\n",
    "langindexID = {}\n",
    "langs = [u'en', u'es', u'pt', u'ca', u'de', u'gl', u'it', u'fr', u'eu']\n",
    "for i in range(len(langs)):\n",
    "    langs[i] = langs[i].decode('utf-8')\n",
    "i=0\n",
    "temp = np.asarray(range(len(langs)))\n",
    "onehots_lang = np_utils.to_categorical(temp)\n",
    "for lang in langs:\n",
    "    print lang\n",
    "    langOnehotID[lang] = onehots_lang[i]\n",
    "    langindexID[lang] = i\n",
    "    i=i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get onehot,index representations and seqlen of sentences\n",
    "def GetOnehotRep(targs, istrain):\n",
    "    OnehotVecs = []\n",
    "    IndexVecs = []\n",
    "    seqLen = []\n",
    "    for lines in targs:\n",
    "        temp = []\n",
    "        tempI = []\n",
    "        tokens = []\n",
    "        if istrain:\n",
    "            tokens = [('<S>').decode('utf-8')] + list(lines) + [('</S>').decode('utf-8')] #list(targs)\n",
    "        else:\n",
    "            tokens = list(lines) + [('</S>').decode('utf-8')] + [('EOS').decode('utf-8')] # EOS added to predict padding character at the end \n",
    "\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                temp1 = vocabOnehotID[token]\n",
    "                temp2 = vocabindexID[token]\n",
    "            except:\n",
    "                temp1 = vocabOnehotID['unk']\n",
    "                temp2 = vocabindexID['unk']\n",
    "            temp.append(temp1)\n",
    "            tempI.append(temp2)\n",
    "        OnehotVecs.append(temp)\n",
    "        IndexVecs.append(tempI)\n",
    "        seqLen.append(len(tokens))\n",
    "    return OnehotVecs, IndexVecs, seqLen\n",
    "\n",
    "## function to get onehot,index representations of lang\n",
    "def GetOnehotLangRep(targs):\n",
    "    OnehotVecs = []\n",
    "    IndexVecs = []\n",
    "    for targ in targs:\n",
    "        OnehotVecs.append(langOnehotID[targ])\n",
    "        IndexVecs.append(langindexID[targ])\n",
    "    return OnehotVecs, IndexVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for batching train data\n",
    "# function to add padding - EOS used as padding string\n",
    "def makeEqlenbatch(temp,isonehot):\n",
    "    ma = max(len(l) for l in temp)\n",
    "    mi = min(len(l) for l in temp)\n",
    "\n",
    "    if ma > mi:\n",
    "        for j in range(len(temp)):\n",
    "            if len(temp[j]) < max:\n",
    "                if isonehot:\n",
    "                    temp[j] = temp[j] + [vocabOnehotID['EOS']]*(ma-len(temp[j]))\n",
    "                else:\n",
    "                    temp[j] = temp[j] + [vocabindexID['EOS']]*(ma-len(temp[j]))\n",
    "        return temp\n",
    "    else:\n",
    "        return temp\n",
    "\n",
    "# get batches of data\n",
    "def getBatches(gloveVecs,langVecs, batch_size,isonehot):\n",
    "    batchList = []\n",
    "    batchLangList = []\n",
    "    for i in range(0,len(gloveVecs),batch_size):\n",
    "        if i + batch_size > len(gloveVecs):\n",
    "            remvals = len(gloveVecs) - i\n",
    "            temp = gloveVecs[i:i+remvals]\n",
    "            tempLang = np.reshape(langVecs[i:i+remvals],(remvals,1))\n",
    "            temp = makeEqlenbatch(temp,isonehot) \n",
    "            batchList.append(temp)\n",
    "            if not isonehot:\n",
    "                batchLangList.append(np.repeat(tempLang,np.shape(temp)[1],axis=1))\n",
    "            print np.shape(temp)\n",
    "        else:\n",
    "            temp = gloveVecs[i:i+batch_size]\n",
    "            tempLang = np.reshape(langVecs[i:i+batch_size],(batch_size,1))\n",
    "            temp = makeEqlenbatch(temp,isonehot) \n",
    "            batchList.append(temp)\n",
    "            print np.shape(temp)\n",
    "            if not isonehot:\n",
    "                batchLangList.append(np.repeat(tempLang,np.shape(temp)[1],axis=1))\n",
    "\n",
    "    return batchList,batchLangList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for language and sequence batching\n",
    "def getLabelBatches(targVec,batch_size):\n",
    "    batchList = []\n",
    "    for i in range(0,len(targVec),batch_size):\n",
    "        if i + batch_size > len(targVec):\n",
    "            remvals = len(targVec) - i\n",
    "            temp = targVec[i:i+remvals]\n",
    "            print np.shape(temp)\n",
    "            batchList.append(temp)\n",
    "        else:\n",
    "            temp = targVec[i:i+batch_size]\n",
    "            batchList.append(temp)\n",
    "            print np.shape(temp)\n",
    "    return batchList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traindata\n",
    "trainsrcOnehot,trainsrcIndex,trainsrcseqLen = GetOnehotRep(df[1],1)\n",
    "traintgtOnehot,traintgtIndex,traintgtseqLen = GetOnehotRep(df[1],0)\n",
    "# langrep\n",
    "trainLangOnehot,trainLangIndex  = GetOnehotLangRep(df[0])\n",
    "\n",
    "trainCaLangOnehot, trainCaLangIndex  = GetOnehotLangRep([u'ca'] * len(df))\n",
    "trainDeLangOnehot, trainDeLangIndex  = GetOnehotLangRep([u'de'] * len(df))\n",
    "trainEnLangOnehot, trainEnLangIndex  = GetOnehotLangRep([u'en'] * len(df))\n",
    "trainEsLangOnehot, trainEsLangIndex  = GetOnehotLangRep([u'es'] * len(df))\n",
    "trainEuLangOnehot, trainEuLangIndex  = GetOnehotLangRep([u'eu'] * len(df))\n",
    "trainFrLangOnehot, trainFrLangIndex  = GetOnehotLangRep([u'fr'] * len(df))\n",
    "trainGlLangOnehot, trainGlLangIndex  = GetOnehotLangRep([u'gl'] * len(df))\n",
    "trainItLangOnehot, trainItLangIndex  = GetOnehotLangRep([u'it'] * len(df))\n",
    "trainPtLangOnehot, trainPtLangIndex  = GetOnehotLangRep([u'pt'] * len(df))\n",
    "\n",
    "trainLangIndexList = [trainEnLangIndex,trainEsLangIndex,trainPtLangIndex,trainCaLangIndex,trainDeLangIndex,trainGlLangIndex,trainItLangIndex,trainFrLangIndex,trainEuLangIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valdata\n",
    "valsrcOnehot,valsrcIndex,valsrcseqLen = GetOnehotRep(df_val[1],1)\n",
    "valtgtOnehot,valtgtIndex,valtgtseqLen = GetOnehotRep(df_val[1],0)\n",
    "# vallangrep - create separate index list for each language\n",
    "valLangOnehot,valLangIndex  = GetOnehotLangRep(df_val[0])\n",
    "\n",
    "valCaLangOnehot, valCaLangIndex  = GetOnehotLangRep([u'ca'] * len(df_val))\n",
    "valDeLangOnehot, valDeLangIndex  = GetOnehotLangRep([u'de'] * len(df_val))\n",
    "valEnLangOnehot, valEnLangIndex  = GetOnehotLangRep([u'en'] * len(df_val))\n",
    "valEsLangOnehot, valEsLangIndex  = GetOnehotLangRep([u'es'] * len(df_val))\n",
    "valEuLangOnehot, valEuLangIndex  = GetOnehotLangRep([u'eu'] * len(df_val))\n",
    "valFrLangOnehot, valFrLangIndex  = GetOnehotLangRep([u'fr'] * len(df_val))\n",
    "valGlLangOnehot, valGlLangIndex  = GetOnehotLangRep([u'gl'] * len(df_val))\n",
    "valItLangOnehot, valItLangIndex  = GetOnehotLangRep([u'it'] * len(df_val))\n",
    "valPtLangOnehot, valPtLangIndex  = GetOnehotLangRep([u'pt'] * len(df_val))\n",
    "\n",
    "valLangIndexList = [valEnLangIndex,valEsLangIndex,valPtLangIndex,valCaLangIndex,valDeLangIndex,valGlLangIndex,valItLangIndex,valFrLangIndex,valEuLangIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdata\n",
    "testsrcOnehot,testsrcIndex,testsrcseqLen = GetOnehotRep(df_test[0],1)\n",
    "testtgtOnehot,testtgtIndex,testtgtseqLen = GetOnehotRep(df_test[0],0)\n",
    "# testlangrep - create separate index list for each language\n",
    "testCaLangOnehot, testCaLangIndex  = GetOnehotLangRep([u'ca'] * len(df_test))\n",
    "testDeLangOnehot, testDeLangIndex  = GetOnehotLangRep([u'de'] * len(df_test))\n",
    "testEnLangOnehot, testEnLangIndex  = GetOnehotLangRep([u'en'] * len(df_test))\n",
    "testEsLangOnehot, testEsLangIndex  = GetOnehotLangRep([u'es'] * len(df_test))\n",
    "testEuLangOnehot, testEuLangIndex  = GetOnehotLangRep([u'eu'] * len(df_test))\n",
    "testFrLangOnehot, testFrLangIndex  = GetOnehotLangRep([u'fr'] * len(df_test))\n",
    "testGlLangOnehot, testGlLangIndex  = GetOnehotLangRep([u'gl'] * len(df_test))\n",
    "testItLangOnehot, testItLangIndex  = GetOnehotLangRep([u'it'] * len(df_test))\n",
    "testPtLangOnehot, testPtLangIndex  = GetOnehotLangRep([u'pt'] * len(df_test))\n",
    "\n",
    "testLangIndexList = [testEnLangIndex,testEsLangIndex,testPtLangIndex,testCaLangIndex,testDeLangIndex,testGlLangIndex,testItLangIndex,testFrLangIndex,testEuLangIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langindexID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexBatches - input characterIndices\n",
    "batch_size = 128\n",
    "trainsrcBatch, trainLangBatch = getBatches(trainsrcIndex, trainLangIndex, batch_size,0)\n",
    "\n",
    "# onehotBatches - output ground truth characters\n",
    "batch_size = 128\n",
    "traintgtBatch, _ = getBatches(traintgtOnehot, trainLangIndex, batch_size,1)\n",
    "\n",
    "# seqlenbatches - batches of seqlen of each sentence\n",
    "trainsrcseqlenBatch = getLabelBatches(trainsrcseqLen,batch_size)\n",
    "traintgtseqlenBatch = getLabelBatches(traintgtseqLen,batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Char RNN model\n",
    "## keras model\n",
    "import keras\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
    "from keras.models import Model, Sequential\n",
    "from keras import optimizers\n",
    "\n",
    "vocab_input = Input(shape=(None,), dtype='int32', name='vocab_input')\n",
    "lang_input = Input(shape = (None,), dtype='int32', name='lang_input')\n",
    "\n",
    "x1 = Embedding(output_dim=15, input_dim=len(vocab), input_length=None)(vocab_input)\n",
    "x2 = Embedding(output_dim=6, input_dim=len(langindexID), input_length=None)(lang_input)\n",
    "\n",
    "x = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "lstm_out = LSTM(32,return_sequences=True)(x)\n",
    "\n",
    "output = TimeDistributed(Dense(len(vocab), activation='softmax'))(lstm_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model = Model(inputs=[vocab_input, lang_input], outputs=[output])\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model for n epochs\n",
    "for epochs in range(50):\n",
    "    print epochs\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for i in range(len(trainsrcBatch)):\n",
    "        inputs = [np.asarray(trainsrcBatch[i]), np.asarray(trainLangBatch[i])]\n",
    "        outputs = np.asarray(traintgtBatch[i])\n",
    "        loss,acc = model.train_on_batch(inputs,outputs)\n",
    "    print loss\n",
    "    print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('charRNN.h5') #haven't saved cause couldnt install libhdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train prediction\n",
    "## output - list of langIDnumbers and langIDs\n",
    "preds_train = np.zeros((len(trainsrcIndex),9))\n",
    "j=0\n",
    "for langs in trainLangIndexList:\n",
    "    print j\n",
    "    for i in range(len(trainsrcIndex)):\n",
    "        c = np.repeat(langs[i],len(trainsrcIndex[i])).tolist()\n",
    "        output_array = model.predict([np.asarray(trainsrcIndex[i]).reshape(1,len(trainsrcIndex[i])), np.asarray(c).reshape(1,len(c))])\n",
    "        predictions = output_array[0]\n",
    "        p = 0\n",
    "        for k in range(predictions.shape[0]):\n",
    "            GTindex = traintgtIndex[i][k]\n",
    "            p = p + np.log(predictions[k][GTindex])\n",
    "        preds_train[i][j] = p\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [u'en', u'es', u'pt', u'ca', u'de', u'gl', u'it', u'fr', u'eu']\n",
    "pred_train_indices = np.argmax(preds_train, axis=1)\n",
    "pred_train_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction accuracy\n",
    "from sklearn import metrics\n",
    "print \"language prediction accuracy on train data\", metrics.accuracy_score(trainLangIndex, pred_train_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction accuracy\n",
    "from sklearn import metrics\n",
    "print \"language prediction accuracy on train data\", metrics.accuracy_score(trainLangIndex, pred_train_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 for each language of validation data\n",
    "en_indexes = [i for i,x in enumerate(trainLangIndex) if x == 0]\n",
    "en_actual = [ trainLangIndex[i] for i in en_indexes ]\n",
    "en_pred = [ pred_train_indices[i] for i in en_indexes ]\n",
    "print \"train - En_f1\", metrics.f1_score(en_actual, en_pred, average='micro')\n",
    "\n",
    "es_indexes = [i for i,x in enumerate(trainLangIndex) if x == 1]\n",
    "es_actual = [ trainLangIndex[i] for i in es_indexes ]\n",
    "es_pred = [ pred_train_indices[i] for i in es_indexes ]\n",
    "print \"train - Es_f1\", metrics.f1_score(es_actual, es_pred, average='micro')\n",
    "\n",
    "pt_indexes = [i for i,x in enumerate(trainLangIndex) if x == 2]\n",
    "pt_actual = [ trainLangIndex[i] for i in pt_indexes ]\n",
    "pt_pred = [ pred_train_indices[i] for i in pt_indexes ]\n",
    "print \"train - Pt_f1\", metrics.f1_score(pt_actual, pt_pred, average='micro')\n",
    "\n",
    "ca_indexes = [i for i,x in enumerate(trainLangIndex) if x == 3]\n",
    "ca_actual = [ trainLangIndex[i] for i in ca_indexes ]\n",
    "ca_pred = [ pred_train_indices[i] for i in ca_indexes ]\n",
    "print \"train - Ca_f1\", metrics.f1_score(ca_actual, ca_pred, average='micro')\n",
    "\n",
    "de_indexes = [i for i,x in enumerate(trainLangIndex) if x == 4]\n",
    "de_actual = [ trainLangIndex[i] for i in de_indexes ]\n",
    "de_pred = [ pred_train_indices[i] for i in de_indexes ]\n",
    "print \"train - train - De_f1\", metrics.f1_score(de_actual, de_pred, average='micro')\n",
    "\n",
    "gl_indexes = [i for i,x in enumerate(trainLangIndex) if x == 5]\n",
    "gl_actual = [ trainLangIndex[i] for i in gl_indexes ]\n",
    "gl_pred = [ pred_train_indices[i] for i in gl_indexes ]\n",
    "print \"train - Gl_f1\", metrics.f1_score(gl_actual, gl_pred, average='micro')\n",
    "\n",
    "it_indexes = [i for i,x in enumerate(trainLangIndex) if x == 6]\n",
    "it_actual = [ trainLangIndex[i] for i in it_indexes ]\n",
    "it_pred = [ pred_train_indices[i] for i in it_indexes ]\n",
    "print \"train - It_f1\", metrics.f1_score(it_actual, it_pred, average='micro')\n",
    "\n",
    "fr_indexes = [i for i,x in enumerate(trainLangIndex) if x == 7]\n",
    "fr_actual = [ trainLangIndex[i] for i in fr_indexes ]\n",
    "fr_pred = [ pred_train_indices[i] for i in fr_indexes ]\n",
    "print \"train - Fr_f1\", metrics.f1_score(fr_actual, fr_pred, average='micro')\n",
    "\n",
    "eu_indexes = [i for i,x in enumerate(trainLangIndex) if x == 8]\n",
    "eu_actual = [ trainLangIndex[i] for i in eu_indexes ]\n",
    "eu_pred = [ pred_train_indices[i] for i in eu_indexes ]\n",
    "print \"train - Eu_f1\", metrics.f1_score(eu_actual, eu_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## val prediction\n",
    "## output list of langIDnumbers and langIDs\n",
    "preds_val = np.zeros((len(valsrcIndex),9))\n",
    "j=0\n",
    "for langs in valLangIndexList:\n",
    "    print j\n",
    "    for i in range(len(valsrcIndex)):\n",
    "        c = np.repeat(langs[i],len(valsrcIndex[i])).tolist()\n",
    "        output_array = model.predict([np.asarray(valsrcIndex[i]).reshape(1,len(valsrcIndex[i])), np.asarray(c).reshape(1,len(c))])\n",
    "        predictions = output_array[0]\n",
    "        #print np.max(predictions[0])\n",
    "        #cc\n",
    "        p = 0\n",
    "        for k in range(predictions.shape[0]):\n",
    "            GTindex = valtgtIndex[i][k]\n",
    "            p = p + np.log(predictions[k][GTindex])\n",
    "        preds_val[i][j] = p\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [u'en', u'es', u'pt', u'ca', u'de', u'gl', u'it', u'fr', u'eu']\n",
    "pred_val_indices = np.argmax(preds_val, axis=1)\n",
    "pred_val_indices = pred_val_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print \"language prediction accuracy on val data\", metrics.accuracy_score(valLangIndex, pred_val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 for each language of validation data\n",
    "en_indexes = [i for i,x in enumerate(valLangIndex) if x == 0]\n",
    "en_actual = [ valLangIndex[i] for i in en_indexes ]\n",
    "en_pred = [ pred_val_indices[i] for i in en_indexes ]\n",
    "print \"val - En_f1\", metrics.f1_score(en_actual, en_pred, average='micro')\n",
    "\n",
    "es_indexes = [i for i,x in enumerate(valLangIndex) if x == 1]\n",
    "es_actual = [ valLangIndex[i] for i in es_indexes ]\n",
    "es_pred = [ pred_val_indices[i] for i in es_indexes ]\n",
    "print \"val - Es_f1\", metrics.f1_score(es_actual, es_pred, average='micro')\n",
    "\n",
    "pt_indexes = [i for i,x in enumerate(valLangIndex) if x == 2]\n",
    "pt_actual = [ valLangIndex[i] for i in pt_indexes ]\n",
    "pt_pred = [ pred_val_indices[i] for i in pt_indexes ]\n",
    "print \"val - Pt_f1\", metrics.f1_score(pt_actual, pt_pred, average='micro')\n",
    "\n",
    "ca_indexes = [i for i,x in enumerate(valLangIndex) if x == 3]\n",
    "ca_actual = [ valLangIndex[i] for i in ca_indexes ]\n",
    "ca_pred = [ pred_val_indices[i] for i in ca_indexes ]\n",
    "print \"val - Ca_f1\", metrics.f1_score(ca_actual, ca_pred, average='micro')\n",
    "\n",
    "de_indexes = [i for i,x in enumerate(valLangIndex) if x == 4]\n",
    "de_actual = [ valLangIndex[i] for i in de_indexes ]\n",
    "de_pred = [ pred_val_indices[i] for i in de_indexes ]\n",
    "print \"val - De_f1\", metrics.f1_score(de_actual, de_pred, average='micro')\n",
    "\n",
    "gl_indexes = [i for i,x in enumerate(valLangIndex) if x == 5]\n",
    "gl_actual = [ valLangIndex[i] for i in gl_indexes ]\n",
    "gl_pred = [ pred_val_indices[i] for i in gl_indexes ]\n",
    "print \"val - Gl_f1\", metrics.f1_score(gl_actual, gl_pred, average='micro')\n",
    "\n",
    "it_indexes = [i for i,x in enumerate(valLangIndex) if x == 6]\n",
    "it_actual = [ valLangIndex[i] for i in it_indexes ]\n",
    "it_pred = [ pred_val_indices[i] for i in it_indexes ]\n",
    "print \"val - It_f1\", metrics.f1_score(it_actual, it_pred, average='micro')\n",
    "\n",
    "fr_indexes = [i for i,x in enumerate(valLangIndex) if x == 7]\n",
    "fr_actual = [ valLangIndex[i] for i in fr_indexes ]\n",
    "fr_pred = [ pred_val_indices[i] for i in fr_indexes ]\n",
    "print \"val - Fr_f1\", metrics.f1_score(fr_actual, fr_pred, average='micro')\n",
    "\n",
    "eu_indexes = [i for i,x in enumerate(valLangIndex) if x == 8]\n",
    "eu_actual = [ valLangIndex[i] for i in eu_indexes ]\n",
    "eu_pred = [ pred_val_indices[i] for i in eu_indexes ]\n",
    "print \"val - Eu_f1\", metrics.f1_score(eu_actual, eu_pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity of validation\n",
    "# gen validation output as chars using argmax method\n",
    "outputs_val = []\n",
    "for i in range(len(valsrcIndex)):\n",
    "    c = np.repeat(valLangIndex[i],len(valsrcIndex[i])).tolist()\n",
    "    output_array = model.predict([np.asarray(valsrcIndex[i]).reshape(1,len(valsrcIndex[i])), np.asarray(c).reshape(1,len(c))])\n",
    "    predictions = output_array[0]\n",
    "    temp = []\n",
    "    for j in range(len(predictions)):\n",
    "        argm = np.argmax(predictions[j])\n",
    "        temp = temp + [vocabindexID.keys()[vocabindexID.values().index(int(argm))]]\n",
    "    outputs_val.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get valperplexity based on train data character distribution\n",
    "def logpofs_val(chars):\n",
    "    tempsum = 0\n",
    "    for char in chars:\n",
    "        if char in vocab:\n",
    "            tempsum = tempsum + np.log2(charprob[char])\n",
    "        else:\n",
    "            tempsum = tempsum + np.log2(charprob['unk'])\n",
    "    tempsum = tempsum #+ np.log2(charprob['</S>']) #no need to add probability of /S because it's present in the predicted sentence\n",
    "    return tempsum\n",
    "\n",
    "def perplexity_val(df, N):\n",
    "    probsum = 0\n",
    "    for i in range(len(df)):\n",
    "        sentence = df[i]\n",
    "        probsum = probsum + logpofs_val(sentence)\n",
    "    return 2**(-1 * probsum / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Perplexity of predicted val data\", perplexity_val(outputs_val,N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "## output list of langIDnumbers and langIDs\n",
    "preds_test = np.zeros((len(testsrcIndex),9))\n",
    "j=0\n",
    "for testLang in testLangIndexList:\n",
    "    print j\n",
    "    for i in range(len(testsrcIndex)):\n",
    "        c = np.repeat(testLang[i],len(testsrcIndex[i])).tolist()\n",
    "        output_array = model.predict([np.asarray(testsrcIndex[i]).reshape(1,len(testsrcIndex[i])), np.asarray(c).reshape(1,len(c))])\n",
    "        predictions = output_array[0]\n",
    "        p = 0\n",
    "        for k in range(predictions.shape[0]):\n",
    "            GTindex = testtgtIndex[i][k]\n",
    "            p = p + np.log(predictions[k][GTindex])\n",
    "        preds_test[i][j] = p\n",
    "    j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [u'en', u'es', u'pt', u'ca', u'de', u'gl', u'it', u'fr', u'eu']\n",
    "pred_test_indices = np.argmax(preds_test, axis=1)\n",
    "pred_test_indices = pred_test_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write test predictions to text file\n",
    "langs = [u'en', u'es', u'pt', u'ca', u'de', u'gl', u'it', u'fr', u'eu']\n",
    "\n",
    "langIDtowrite = []\n",
    "for i in pred_test_indices:\n",
    "    langIDtowrite.append(langs[i])\n",
    "\n",
    "a = np.asarray(langIDtowrite)    \n",
    "a = a.astype(str)\n",
    "np.savetxt('test.ids_new',a,fmt='%s')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
